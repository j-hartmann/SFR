{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8aqd/2AiF1UTUKA5MQ3wj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-hartmann/SFR/blob/main/SFR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Appendix\n",
        "\n",
        "## **Using Text Analysis in Service Failure Recovery: Theory, Workflows, and Models**\n",
        "\n",
        "#### Villarroel Ordenes, Packard, Proserpio, and Hartmann (2024)"
      ],
      "metadata": {
        "id": "9rikK3sDyFiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dictionaries**"
      ],
      "metadata": {
        "id": "BStVS62aCwZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "rQyrKdK1ElRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "z50kH7-XFSs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example sentences\n",
        "sentences = [\"I'm disappointed and frustrated how ABC treat their customers...\", \"The service experience was not bad\", \"AMAZING üòç\"]\n",
        "\n",
        "# extract sentiment\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "for sentence in sentences:\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    print(\"{:-<65} {}\".format(sentence, str(vs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfSM_38oCzEy",
        "outputId": "9321e2c9-9477-4858-e71d-ecc7e0bc48c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm disappointed and frustrated how ABC treat their customers...- {'neg': 0.428, 'neu': 0.395, 'pos': 0.178, 'compound': -0.5859}\n",
            "The service experience was not bad------------------------------- {'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n",
            "AMAZING üòç-------------------------------------------------------- {'neg': 0.0, 'neu': 0.285, 'pos': 0.715, 'compound': 0.8192}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic Models**"
      ],
      "metadata": {
        "id": "uYGJ1-D6CzhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install lda"
      ],
      "metadata": {
        "id": "P8OLgLKyEBiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import lda\n",
        "import lda.datasets\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bYGegTuwC01N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X = lda.datasets.load_reuters()\n",
        "vocab = lda.datasets.load_reuters_vocab()\n",
        "titles = lda.datasets.load_reuters_titles()"
      ],
      "metadata": {
        "id": "8lrHJROGELpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run topic model\n",
        "model = lda.LDA(n_topics=10, n_iter=1500, random_state=42)\n",
        "model.fit(X)\n",
        "topic_word = model.topic_word_\n",
        "n_top_words = 8\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "  print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
      ],
      "metadata": {
        "id": "M_J1efiCFrl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised Machine Learning and Deep Learning**"
      ],
      "metadata": {
        "id": "CDAZaeIFC-lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "kebIkkuZEFLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "wFk_miM1DA4m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import data\n",
        "drug_reviews_drugs_com = fetch_ucirepo(id=462)\n",
        "data = drug_reviews_drugs_com.data.features\n",
        "\n",
        "# clean data\n",
        "data['review_clean']=data['review'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "data = data.fillna({'review':''})\n",
        "\n",
        "# create a sentiment label column\n",
        "data['sentiment'] = data['rating'].apply(lambda rating : +1 if rating > 5 else -1)\n",
        "\n",
        "# create a train and test split\n",
        "train_data, test_data = train_test_split(data, test_size = 0.20)\n",
        "print('Size of train_data is :', train_data.shape)\n",
        "print('Size of test_data is :', test_data.shape)"
      ],
      "metadata": {
        "id": "BTkghf5HF4BQ",
        "outputId": "64cb7f2c-aa6d-4759-f6da-cbbcf3f68081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train_data is : (172050, 8)\n",
            "Size of test_data is : (43013, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features (vectorize)\n",
        "vectorizer = HashingVectorizer()\n",
        "train_matrix = vectorizer.transform(train_data['review_clean'].values.astype('U'))\n",
        "test_matrix = vectorizer.transform(test_data['review_clean'].values.astype('U'))\n",
        "\n",
        "# train random forest\n",
        "random_forest = RandomForestClassifier()\n",
        "model = random_forest.fit(train_matrix, train_data['sentiment'])\n",
        "\n",
        "# predict and measure performance on test data\n",
        "y_pred = model.predict(test_matrix)\n",
        "f1_score(y_pred, test_data['sentiment'])"
      ],
      "metadata": {
        "id": "PPIcttqbGWKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embeddings**"
      ],
      "metadata": {
        "id": "IOe3szn2DCge"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Xp8d8z9DDNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Language Models and Generative AI**"
      ],
      "metadata": {
        "id": "vigQnoOnDDtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "NGz4i-38z07Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run SiEBERT, a language model specialized on binary sentiment analysis.*"
      ],
      "metadata": {
        "id": "ng_-2RM5ykuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qm_p64iyE8Q"
      },
      "outputs": [],
      "source": [
        "# import model\n",
        "get_sentiment = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment\n",
        "get_sentiment(\"My flight was cancelled. Where can I request a refund?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oYh8rRYyjUf",
        "outputId": "c3e0f393-b3b7-48b2-8098-ac18c15e133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9993242025375366}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run a fine-tuned language model for emotion extraction.*"
      ],
      "metadata": {
        "id": "6liv2s9FzWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "get_emotions = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)"
      ],
      "metadata": {
        "id": "xPcqe92PzJTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict emotions\n",
        "get_emotions(\"This was by far the best service experience I've ever made!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPJbFPw9zRzP",
        "outputId": "ee263e43-e0c4-4ef7-f758-1f81ef0b912f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'anger', 'score': 0.005697187967598438},\n",
              "  {'label': 'disgust', 'score': 0.005230925511568785},\n",
              "  {'label': 'fear', 'score': 0.0024537532590329647},\n",
              "  {'label': 'joy', 'score': 0.7304487228393555},\n",
              "  {'label': 'neutral', 'score': 0.09406807273626328},\n",
              "  {'label': 'sadness', 'score': 0.002163215074688196},\n",
              "  {'label': 'surprise', 'score': 0.15993811190128326}]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run Microsoft's Phi-3-mini for zero-shot aspect-based sentiment analysis.*"
      ],
      "metadata": {
        "id": "k2Y6TbycbrIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3vSSt5J2jcE",
        "outputId": "cbd73523-7d7f-45fe-bf09-724edb8961cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 23 12:07:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0              26W /  70W |   4815MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "t_70wvDBabgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "9nF7Vg2glwSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}"
      ],
      "metadata": {
        "id": "upvXUFohnxY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Your task is to predict the sentiment of the following sentence: 'I'm disappointed by the service quality but pleasantly surprised by the price.'. Return the sentiment (positive, negative, neutral, or mixed) and the respective aspect of the sentiment in JSON format. Report the sentiment for each aspect separately.\"},\n",
        "]\n",
        "\n",
        "output = pipe(messages, **generation_args)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeXU1t27nF8s",
        "outputId": "b9a9be13-d521-415c-b509-9378428ae9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " {\n",
            "  \"overall_sentiment\": \"mixed\",\n",
            "  \"aspects\": {\n",
            "    \"service_quality\": {\n",
            "      \"sentiment\": \"negative\",\n",
            "      \"reason\": \"disappointed\"\n",
            "    },\n",
            "    \"price\": {\n",
            "      \"sentiment\": \"positive\",\n",
            "      \"reason\": \"pleasantly surprised\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References and Resources:**\n",
        "* https://github.com/cjhutto/vaderSentiment\n",
        "* https://github.com/lda-project/lda\n",
        "* https://huggingface.co/siebert/sentiment-roberta-large-english\n",
        "* https://huggingface.co/j-hartmann/emotion-english-distilroberta-base\n",
        "* https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\n",
        "* Krugmann, J.O., Hartmann, J. Sentiment Analysis in the Age of Generative AI. *Customer Needs and Solutions* 11, 3 (2024). https://doi.org/10.1007/s40547-024-00143-4.\n"
      ],
      "metadata": {
        "id": "FqvTATYpcbZM"
      }
    }
  ]
}