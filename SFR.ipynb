{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM23scP2dBhxhRYEymdrYrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-hartmann/SFR/blob/main/SFR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SFR**"
      ],
      "metadata": {
        "id": "9rikK3sDyFiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "NGz4i-38z07Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run SiEBERT, a language model specialized on binary sentiment analysis.*"
      ],
      "metadata": {
        "id": "ng_-2RM5ykuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qm_p64iyE8Q"
      },
      "outputs": [],
      "source": [
        "# import model\n",
        "get_sentiment = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment\n",
        "get_sentiment(\"My flight was cancelled. Where can I request a refund?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oYh8rRYyjUf",
        "outputId": "c3e0f393-b3b7-48b2-8098-ac18c15e133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9993242025375366}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run a fine-tuned language model for emotion extraction.*"
      ],
      "metadata": {
        "id": "6liv2s9FzWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "get_emotions = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)"
      ],
      "metadata": {
        "id": "xPcqe92PzJTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict emotions\n",
        "get_emotions(\"This was by far the best service experience I've ever made!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPJbFPw9zRzP",
        "outputId": "ee263e43-e0c4-4ef7-f758-1f81ef0b912f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'anger', 'score': 0.005697187967598438},\n",
              "  {'label': 'disgust', 'score': 0.005230925511568785},\n",
              "  {'label': 'fear', 'score': 0.0024537532590329647},\n",
              "  {'label': 'joy', 'score': 0.7304487228393555},\n",
              "  {'label': 'neutral', 'score': 0.09406807273626328},\n",
              "  {'label': 'sadness', 'score': 0.002163215074688196},\n",
              "  {'label': 'surprise', 'score': 0.15993811190128326}]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run Meta's Llama 2 for zero-shot sentiment analysis.*"
      ],
      "metadata": {
        "id": "k2Y6TbycbrIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3vSSt5J2jcE",
        "outputId": "cbd73523-7d7f-45fe-bf09-724edb8961cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 23 12:07:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0              26W /  70W |   4815MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "t_70wvDBabgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "V5b6Qh8Lb32N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "access_token = \"\"  # add access token from Hugging Face after requesting access to Llama 2: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_4bit=True, use_auth_token=access_token)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, use_auth_token=access_token)"
      ],
      "metadata": {
        "id": "rcnD0ENuaTYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment\n",
        "prompt = \"Your task is to predict the sentiment of the following sentence. The sentence is either positive or negative. 'I'm disappointed by the service quality'. Return only positive or negative.\"\n",
        "model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "output = model.generate(**model_inputs)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbNWS-SX0pGS",
        "outputId": "0470434c-9b37-4a68-9eaa-8311a93b0ece"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your task is to predict the sentiment of the following sentence. The sentence is either positive or negative. 'I'm disappointed by the service quality'. Return only positive or negative.\n",
            "\n",
            "Example: If the sentence is 'I'm disappointed by the service quality', then the sentiment is negative.\n",
            "\n",
            "Please let me know if you have any questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References & Resources:**\n",
        "* https://huggingface.co/siebert/sentiment-roberta-large-english\n",
        "* https://huggingface.co/j-hartmann/emotion-english-distilroberta-base\n",
        "* https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "* https://colab.research.google.com/drive/1X1z9Q6domMKl2CnEM0QGHNwidLfR4dW2?usp=sharing#scrollTo=THqfvzHIjSK9\n",
        "* Krugmann, J.O., Hartmann, J. Sentiment Analysis in the Age of Generative AI. *Customer Needs and Solutions* 11, 3 (2024). https://doi.org/10.1007/s40547-024-00143-4.\n"
      ],
      "metadata": {
        "id": "FqvTATYpcbZM"
      }
    }
  ]
}